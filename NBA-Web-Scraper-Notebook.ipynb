{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5b4a76",
   "metadata": {},
   "source": [
    "# NBA Stats Web Scraper Notebook\n",
    "\n",
    "## Luke DiPerna\n",
    "\n",
    "This notebook displays the code I used to scrape NBA boxscore data from [basketball-reference](https://www.basketball-reference.com/) and create a SQLite database which can be found on [Kaggle](https://www.kaggle.com/datasets/lukedip/nba-boxscore-dataset).\n",
    "\n",
    "WARNING: The runtime is extremely long and this notebook should not be run unless you understand the implications of the code below.\n",
    "\n",
    "Basketball-Reference does allow web scraping, and I have taken the necessary steps to follow web scraping best practices and ensure that the scraper does not violate the website terms and conditions (as of the time of writing this), which can be found [here](https://www.sports-reference.com/bot-traffic.html). However, these terms could change and it is imperative that you check before running this code. Even with these safeguards, it is possible that you will still run into issues with interruptions, so you may need to take additional steps such as lengthen the delay or use a VPN with a rotating IP.\n",
    "\n",
    "The data consists of team and player boxscore statistics from each regular season game. In order to collect the data, the scraper collects the urls for each game, accesses the webpage using Selenium, processes and stores the data in dataframes, and then adds the processed data to the database. A typical game stats webpage looks like [this](https://www.basketball-reference.com/boxscores/201610260LAL.html). There are a lot of data tables on the page, but I am focused on four in particular: home team boxscore, home team advanced boxscore, away team boxscore, and away team advanced boxscore. The scraper collects these stats, along with some game meta-information, and includes them in the database. I also feature engineered the PIE (Player Impact Estimate) statistic for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc70d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# used to create id strings later\n",
    "base_url = 'https://www.basketball-reference.com'\n",
    "\n",
    "season_gamecount = 1\n",
    "\n",
    "precovid_seasons = ['1314', '1415', '1516', '1617', '1718', '1819']\n",
    "precovid_url_years = ['2014', '2015', '2016', '2017', '2018', '2019']\n",
    "postcovid_seasons = ['1920', '2021', '2122', '2223']\n",
    "postcovid_url_years = ['2020', '2021', '2022', '2023']\n",
    "\n",
    "post_covid_season_dict = {'1920': {'month_len': 8, 'final_month_gamecount': 83},\n",
    "                          '2021': {'month_len': 6, 'final_month_gamecount': 140},\n",
    "                          '2122': {'month_len': 7, 'final_month_gamecount': 83},\n",
    "                          '2223': {'month_len': 7, 'final_month_gamecount': 72}\n",
    "                         }\n",
    "# used to create sql database table columns\n",
    "info_columns = ['game_id', 'season', 'date', 'away_team', 'away_score', 'home_team', 'home_score', 'result']\n",
    "num_columns = ['FG', 'FGA', '3P', '3PA', 'FT', 'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', '+/-',\n",
    "               'FG%', '3P%', 'FT%', 'TS%', 'eFG%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'ORtg', 'DRtg', 'BPM']\n",
    "# pause between each server call\n",
    "delay = time.sleep(np.random.randint(3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39beb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game_info(url, season_id, season_gamecount):\n",
    "    \n",
    "    game_count = str(season_gamecount)\n",
    "    while len(game_count) < 4:\n",
    "        game_count = '0' + game_count\n",
    "    \n",
    "    id_string = url.strip(string.ascii_letters+string.punctuation)\n",
    "    year = id_string[0:4]\n",
    "    month = id_string[4:6]\n",
    "    day = id_string[6:8]\n",
    "    \n",
    "    date = year+'-'+month+'-'+day\n",
    "    \n",
    "    game_id = int(season_id+month+day+game_count)\n",
    "    season_id = int(season_id)\n",
    "    \n",
    "    return [game_id, season_id, date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7282e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_info(table):\n",
    "    '''\n",
    "    Create a dataframe with game results. Uses an html table as input.\n",
    "    \n",
    "    ---\n",
    "    Inputs:\n",
    "    \n",
    "    table: a BeautifulSoup html table\n",
    "    ---\n",
    "    Outputs:\n",
    "    \n",
    "    team_info: a dataframe with the relevant game information (team_ids, scores, and boolean 'results' column)\n",
    "    '''\n",
    "    \n",
    "    # get team_ids\n",
    "    id_rows = table.findAll('th', attrs={'class':'center', 'data-stat':'team', 'scope':'row'})\n",
    "    team_ids = [row.text.strip() for row in id_rows]\n",
    "    \n",
    "    # get final score\n",
    "    scores = table.findAll('td', attrs={'class': 'center', 'data-stat': 'T'})\n",
    "    final_scores = [int(score.text.strip()) for score in scores]\n",
    "    \n",
    "    # boolean game-winner: away=0, home=1\n",
    "    if final_scores[0] > final_scores[1]:\n",
    "        result=0\n",
    "    else:\n",
    "        result=1\n",
    "    \n",
    "    team_info = [team_ids[0], final_scores[0], team_ids[1], final_scores[1], result]\n",
    "    \n",
    "    return team_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_df(game_info, team_info, info_columns):\n",
    "    info = game_info + team_info\n",
    "    info_df = pd.DataFrame([info], columns=info_columns)\n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxscores(table, game_id):\n",
    "\n",
    "    # ignore first 'tr', it is table title, not column\n",
    "    rows = table.findAll('tr')[1:]\n",
    "    # first 'th' is 'Starters', but will be changed into the player names\n",
    "    headers = rows[0].findAll('th')\n",
    "    # provide column names\n",
    "    headerlist = [h.text.strip() for h in headers]\n",
    "    \n",
    "    # ignore first row (headers)\n",
    "    data = rows[1:]\n",
    "    # get names column\n",
    "    player_names = [row.find('th').text.strip() for row in rows]\n",
    "    # get player stats\n",
    "    player_stats = [[stat.text.strip() for stat in row.findAll('td')] for row in data]\n",
    "    # add player name as first entry in each row\n",
    "    for i in range(len(player_stats)):\n",
    "        # ignore header with i+1\n",
    "        player_stats[i].insert(0, player_names[i+1])\n",
    "    \n",
    "    # create player stats dataframe\n",
    "    player_box_df = pd.DataFrame(player_stats, columns=headerlist)\n",
    "    # drop 'Reserves' row\n",
    "    player_box_df.drop(player_box_df[player_box_df['Starters'] == 'Reserves'].index, inplace=True)\n",
    "    \n",
    "    # add game id column\n",
    "    player_box_df.insert(loc=0, column='game_id', value=game_id)\n",
    "    \n",
    "    # create team stats dataframe from last row in player stats\n",
    "    team_box_df = pd.DataFrame(player_box_df.iloc[-1]).T\n",
    "    \n",
    "    #drop team totals from player stats df\n",
    "    player_box_df = player_box_df[:-1].rename(columns={'Starters': 'player'})\n",
    "\n",
    "    return player_box_df, team_box_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxscores(boxscore_list, team_ids, scope):\n",
    "\n",
    "    # create tuple for every 2 boxscores in list\n",
    "    pairs = [((boxscore_list[i]), (boxscore_list[i + 1])) for i in range(0, len(boxscore_list), 2)]\n",
    "    \n",
    "    clean_boxscores= []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        \n",
    "        # combine regular and adv boxscores\n",
    "        df = pd.concat([*pair], axis=1)\n",
    "        # drop columns with duplicate names\n",
    "        df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "        \n",
    "        clean_boxscores.append(df)\n",
    "    \n",
    "    for i in range(len(clean_boxscores)):\n",
    "        \n",
    "        if scope=='team':\n",
    "            clean_boxscores[i].rename(columns={'Starters': 'team'}, inplace=True)\n",
    "            clean_boxscores[i]['team'] = team_ids[i]\n",
    "            \n",
    "        elif scope=='player':\n",
    "            clean_boxscores[i].insert(loc=2, column='team', value=team_ids[i])\n",
    "    \n",
    "    return clean_boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd88af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df, num_columns):\n",
    "\n",
    "    df.replace(to_replace='', value='-99', inplace=True)\n",
    "    \n",
    "    for column in num_columns:\n",
    "        df[column] = df[column].astype('float64')\n",
    "        \n",
    "    df.replace(to_replace=-99, value=np.nan, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92223d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PIE(player_boxes, totals):\n",
    "    \n",
    "    PIE_denom = (totals['PTS'] + totals['FG'] + totals['FT'] - totals['FGA'] - totals['FTA'] + totals['DRB'] + (0.5*totals['ORB']) + totals['AST'] + totals['STL'] + (0.5*totals['BLK']) - totals['PF'] - totals['TOV'])\n",
    "    player_boxes['PIE'] = round((100 * (player_boxes['PTS'] + player_boxes['FG'] + player_boxes['FT'] - player_boxes['FGA'] - player_boxes['FTA'] + player_boxes['DRB'] + (0.5*player_boxes['ORB']) + player_boxes['AST'] + player_boxes['STL'] + (0.5*player_boxes['BLK']) - player_boxes['PF'] - player_boxes['TOV']) / PIE_denom), 1)\n",
    "    \n",
    "    return player_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sql database\n",
    "conn = sqlite3.connect('data/temp/NBA-Game-Database-temp')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(precovid_seasons)):\n",
    "    \n",
    "    season_id = precovid_seasons[i]\n",
    "    season_gamecount = 1\n",
    "    start_url = 'https://www.basketball-reference.com/leagues/NBA_' + precovid_url_years[i] + '_games.html'\n",
    "    \n",
    "    # open the season schedule page\n",
    "    driver.get(start_url)\n",
    "    # delay between each server call\n",
    "    delay\n",
    "    src = driver.page_source\n",
    "    # create beautiful soup object from html/xml\n",
    "    parser = BeautifulSoup(src, 'lxml')\n",
    "    \n",
    "    # every month from the season\n",
    "    months = parser.find('div', attrs = {'class': 'filter'})\n",
    "    # partial urls for each month\n",
    "    links = months.findAll('a')\n",
    "    # full urls for each month\n",
    "    month_links = [base_url + link['href'] for link in links]\n",
    "    # only include regular season months (oct-apr)\n",
    "    month_links = month_links[0:7]\n",
    "    \n",
    "    for month_url in month_links:\n",
    "        \n",
    "        # create new browser instance to reduce chance of interruptions\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        delay\n",
    "        driver.get(month_url)\n",
    "        delay\n",
    "        src = driver.page_source\n",
    "        parser = BeautifulSoup(src, 'lxml')\n",
    "        table = parser.find('div', attrs = {'class': 'table_container is_setup'})\n",
    "        \n",
    "        # check if final month (apr). if true, set limit for game_urls before playoffs start\n",
    "        row_num = None\n",
    "        splits = table.findAll('tr', attrs = {'class': 'thead'})\n",
    "        for split in splits:\n",
    "            if 'Playoffs' in split.text:\n",
    "                row_num = int(split['data-row'])\n",
    "                \n",
    "        # get partial urls of every game in the month (if apr, stop before playoffs)\n",
    "        if row_num == None:\n",
    "            game_partial_urls = table.findAll('td', attrs = {'class': 'center', 'data-stat': 'box_score_text'})\n",
    "        elif row_num != None:\n",
    "            game_partial_urls = table.findAll('td', attrs = {'class': 'center', 'data-stat': 'box_score_text'}, limit=row_num)\n",
    "        \n",
    "        game_urls = [base_url + url.a['href'] for url in game_partial_urls]\n",
    "        \n",
    "        # open every game url, retrieve and manipulate data, add to sql database\n",
    "        for i in range(len(game_urls)):\n",
    "    \n",
    "            driver.get(game_urls[i])\n",
    "            delay\n",
    "            src = driver.page_source\n",
    "            parser = BeautifulSoup(src, 'lxml')\n",
    "            \n",
    "            # game_info database:\n",
    "            \n",
    "            id_table = parser.find('table', attrs = {'class': 'suppress_all stats_table', 'id': 'line_score'})\n",
    "            game_info = create_game_info(url=game_urls[i],\n",
    "                                         season_id=season_id,\n",
    "                                         season_gamecount=season_gamecount)\n",
    "            # will use game_id with create_boxscores()\n",
    "            game_id = game_info[0]\n",
    "            team_info = create_team_info(id_table)\n",
    "            # will use team_ids with merge_boxscores()\n",
    "            team_ids = [team_info[0], team_info[2]]\n",
    "            \n",
    "            info_df = create_info_df(game_info=game_info,\n",
    "                                     team_info=team_info,\n",
    "                                     info_columns=info_columns)\n",
    "            # write game info to sql database\n",
    "            info_df.to_sql('game_info', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # team/player databases:\n",
    "            \n",
    "            # 4 boxscore tables : away_box, away_box_adv, home_box, home_box_adv\n",
    "            stat_tables = parser.findAll('table', attrs = {'class': 'sortable stats_table now_sortable'})\n",
    "            \n",
    "            player_box_list = [None, None, None, None]\n",
    "            team_box_list = [None, None, None, None]\n",
    "\n",
    "            # create team and player boxscores\n",
    "            for i in range(len(stat_tables)):\n",
    "                # split player and team boxscores\n",
    "                player_box_list[i], team_box_list[i] = create_boxscores(stat_tables[i], game_id=game_id)\n",
    "            \n",
    "            # team_stats database:\n",
    "            \n",
    "            # combine boxscore and advanced boxscore for each team\n",
    "            away_team_box, home_team_box = merge_boxscores(team_box_list, team_ids=team_ids, scope='team')\n",
    "            team_boxes = pd.concat([away_team_box, home_team_box])\n",
    "            team_boxes.reset_index(drop=True, inplace=True)\n",
    "            # prepare numeric data\n",
    "            team_boxes = change_dtypes(team_boxes, num_columns)\n",
    "            # write to sql database\n",
    "            team_boxes.to_sql('team_stats', con=conn, if_exists='append', index=False)\n",
    "            \n",
    "            # player_stats database:\n",
    "            \n",
    "            # combine boxscore and advanced boxscore for each team\n",
    "            away_player_box, home_player_box = merge_boxscores(player_box_list, team_ids=team_ids, scope='player')\n",
    "            player_boxes = pd.concat([away_player_box, home_player_box])\n",
    "            player_boxes.reset_index(drop=True, inplace=True)\n",
    "            # prepare numeric data\n",
    "            player_boxes = change_dtypes(player_boxes, num_columns)\n",
    "            # create team totals for PIE calculation\n",
    "            totals = dict(team_boxes.loc[:,'FG':'PTS'].sum())\n",
    "            # add PIE column to player boxscore\n",
    "            player_boxes = create_PIE(player_boxes, totals)\n",
    "            # write to sql database\n",
    "            player_boxes.to_sql('player_stats', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # increase gamecount to create next game_id\n",
    "            season_gamecount += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f321be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(postcovid_seasons)):\n",
    "    \n",
    "    season_id = postcovid_seasons[i]\n",
    "    season_gamecount = 1\n",
    "    start_url = 'https://www.basketball-reference.com/leagues/NBA_' + postcovid_url_years[i] + '_games.html'\n",
    "    \n",
    "    # open the season schedule page\n",
    "    driver.get(start_url)\n",
    "    delay\n",
    "    src = driver.page_source\n",
    "    # create beautiful soup object from html/xml\n",
    "    parser = BeautifulSoup(src, 'lxml')\n",
    "    \n",
    "    # every month from the season\n",
    "    months = parser.find('div', attrs = {'class': 'filter'})\n",
    "    # partial urls for each month\n",
    "    links = months.findAll('a')\n",
    "    # full urls for each month\n",
    "    month_links = [base_url + link['href'] for link in links]\n",
    "    # only include regular season months\n",
    "    month_links = month_links[0:post_covid_season_dict[season_id]['month_len']]\n",
    "    \n",
    "    for month_url in month_links:\n",
    "        \n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        delay\n",
    "        \n",
    "        driver.get(month_url)\n",
    "        delay\n",
    "        src = driver.page_source\n",
    "        parser = BeautifulSoup(src, 'lxml')\n",
    "        table = parser.find('div', attrs = {'class': 'table_container is_setup'})\n",
    "        \n",
    "      \n",
    "        # check if final month. if true, set limit for game_urls before playoffs start        \n",
    "        if month_url != month_links[-1]:\n",
    "            game_partial_urls = table.findAll('td', attrs = {'class': 'center', 'data-stat': 'box_score_text'})\n",
    "        else:\n",
    "            play_in = table.find('td', string='Play-In Game').find_parent()\n",
    "            play_in_row = int(play_in['data-row'])\n",
    "            body= table.find('tbody')\n",
    "            all_rows = body.findAll('tr', limit=play_in_row)\n",
    "            \n",
    "            game_rows = []\n",
    "            for row in all_rows:\n",
    "                try:\n",
    "                    row['class']\n",
    "                except KeyError:\n",
    "                    game_rows.append(row)\n",
    "                else:\n",
    "                    pass\n",
    "            game_partial_urls = [row.find(attrs = {'class': 'center', 'data-stat': 'box_score_text'}) for row in game_rows]\n",
    "        \n",
    "        # get game_urls\n",
    "        game_urls = [base_url + url.a['href'] for url in game_partial_urls]\n",
    "        \n",
    "        # open every game url, retrieve and manipulate data, add to sql database\n",
    "        for i in range(len(game_urls)):\n",
    "    \n",
    "            driver.get(game_urls[i])\n",
    "            delay\n",
    "            src = driver.page_source\n",
    "            parser = BeautifulSoup(src, 'lxml')\n",
    "            \n",
    "            # game_info database:\n",
    "            \n",
    "            id_table = parser.find('table', attrs = {'class': 'suppress_all stats_table', 'id': 'line_score'})\n",
    "            game_info = create_game_info(url=game_urls[i],\n",
    "                                         season_id=season_id,\n",
    "                                         season_gamecount=season_gamecount)\n",
    "            # will use game_id with create_boxscores()\n",
    "            game_id = game_info[0]\n",
    "            team_info = create_team_info(id_table)\n",
    "            # will use team_ids with merge_boxscores()\n",
    "            team_ids = [team_info[0], team_info[2]]\n",
    "            info_df = create_info_df(game_info=game_info,\n",
    "                                     team_info=team_info,\n",
    "                                     info_columns=info_columns)\n",
    "            # write to sql database\n",
    "            info_df.to_sql('game_info', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # team/player databases:\n",
    "            \n",
    "            # 4 boxscore tables : away_box, away_box_adv, home_box, home_box_adv\n",
    "            stat_tables = parser.findAll('table', attrs = {'class': 'sortable stats_table now_sortable'})\n",
    "            \n",
    "            player_box_list = [None, None, None, None]\n",
    "            team_box_list = [None, None, None, None]\n",
    "\n",
    "            # create team and player boxscores\n",
    "            for i in range(len(stat_tables)):\n",
    "                # split player and team boxscores\n",
    "                player_box_list[i], team_box_list[i] = create_boxscores(stat_tables[i], game_id=game_id)\n",
    "            \n",
    "            # team_stats database:\n",
    "            \n",
    "            # combine boxscore and advanced boxscore for each team\n",
    "            away_team_box, home_team_box = merge_boxscores(team_box_list, team_ids=team_ids, scope='team')\n",
    "            team_boxes = pd.concat([away_team_box, home_team_box])\n",
    "            team_boxes.reset_index(drop=True, inplace=True)\n",
    "            # prepare numeric data\n",
    "            team_boxes = change_dtypes(team_boxes, num_columns)\n",
    "            # write to sql database\n",
    "            team_boxes.to_sql('team_stats', con=conn, if_exists='append', index=False)\n",
    "            \n",
    "            # player_stats database:\n",
    "            \n",
    "            # combine boxscore and advanced boxscore for each team\n",
    "            away_player_box, home_player_box = merge_boxscores(player_box_list, team_ids=team_ids, scope='player')\n",
    "            player_boxes = pd.concat([away_player_box, home_player_box])\n",
    "            player_boxes.reset_index(drop=True, inplace=True)\n",
    "            # prepare numeric data\n",
    "            player_boxes = change_dtypes(player_boxes, num_columns)\n",
    "            # create team totals for PIE calculation\n",
    "            totals = dict(team_boxes.loc[:,'FG':'PTS'].sum())\n",
    "            # add PIE column to player boxscore\n",
    "            player_boxes = create_PIE(player_boxes, totals)\n",
    "            # write to sql database\n",
    "            player_boxes.to_sql('player_stats', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # increase gamecount to create next game_id\n",
    "            season_gamecount += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper-env",
   "language": "python",
   "name": "scraper-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
